---
title: "Joppa"
output:
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r DoNotModify, include=FALSE}
### Utilities. Do not modify.
# Installation of packages if necessary
InstallPackages <- function(Packages) {
  InstallPackage <- function(Package) {
    if (!Package %in% installed.packages()[, 1]) {
      install.packages(Package, repos="https://cran.rstudio.com/")
    }
  }
  invisible(sapply(Packages, InstallPackage))
}
# Basic packages
InstallPackages(c("rmarkdown", "formatR", "kableExtra", "ragg"))
library("kableExtra") # Mandatory to load css and more
# Chunk font size hook: allows size='small' or any valid Latex font size in chunk options
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r Options, include=FALSE}
### Customized options for this document
# Add necessary packages here
Packages <- c("tidyverse")
# Install them
InstallPackages(Packages)
# knitr options
knitr::opts_chunk$set(
  cache=FALSE, # Cache chunk results
  echo = TRUE, # Show R chunks
  warning=FALSE, # Hide warnings
  # Books only: figures with side captions
  # fig.env='SCfigure', fig.asp=.75,
  # Figure alignment and size
  fig.align='center', out.width='80%',
  # Graphic device
  dev = "ragg_png",
  # Code chunk format
  tidy=TRUE, tidy.opts=list(blank=FALSE, width.cutoff=80),
  size="scriptsize", knitr.graphics.auto_pdf = TRUE
  )
options(width=80)
# ggplot style
library("tidyverse")
theme_set(theme_bw())
theme_update(panel.background=element_rect(fill="transparent", colour=NA),
             plot.background=element_rect(fill="transparent", colour=NA))
knitr::opts_chunk$set(dev.args=list(bg="transparent"))
# Random seed
set.seed(973)
```

# Génération des données

Les paramètres du modèle sont:

- le nombre total d'espèces,
```{r}
S_T <- 81000
```

- la proportion des espèces inconnues identifiées par unité de temps (5ans) et par taxonomiste au début de la période d'étude,
```{r}
beta_1 <- 20/S_T
```

- l'augmentation annuelle de cette proportion
```{r}
beta_2 <- beta_1/100
```


Les paramètres de la simulation sont:

- Le nombre d'unités de temps pour lequel les données sont disponibles,
```{r}
nTemps <- 50
```

- L'erreur du modèle.
```{r}
sigma <- 0.2
```


Les données sont :

-  Le nombre d'unités de temps passé depuis le début de la période d'étude $Y_i=i$ pour $i \in [1, nTemps]$,
```{r}
Y <- 1:nTemps
```

- Le nombre cumulé d'espèces découvertes, qui augmente à chaque unité de temps,
```{r}
sum_S <- numeric(nTemps+1)
# Valeur initiale
sum_S[1] <- 200
```


- Le nombre de taxonomistes actifs $T_i$ à chaque unité de temps, simulé par un modèle log-linéaire.
```{r}
# 10 au début, 100 à la fin, bruité
T <- 10^(1 + Y/nTemps + rnorm(length(Y), sd=0.02))
# Figure
tibble(Y, T) %>% 
  ggplot() +
    geom_line(aes(x=Y, y=T)) +
    scale_y_log10()
```


Le logarithme du nombre d'espèces découvertes à chaque unité de temps est donné par le modèle
$$ \log{S_i} = \log{\left( S_T \beta_1 T_i + \beta_2 S_T T_i Y_i + \beta_1 T_i \sum{S_i} - \beta_2 T_i Y_i \sum{S_i} \right)} 
             + \mathcal{N}\left(0, \sigma \right)$$

Il doit être simulé pas à pas à cause du terme $\sum{S_i}$, le cumul du nombres d'espèces découvertes.
```{r}
# Stockage des S_i
S <- numeric(nTemps)
# Calcul de S_i à chaque temps
for (i in 1:nTemps) {
  S[i] <- exp(log(S_T*beta_1*T[i] 
                    + beta_2*S_T*T[i]*Y[i] 
                    + beta_1*T[i]*sum_S[i] 
                    + beta_2*T[i]*Y[i]*sum_S[i]) 
                + rnorm(1, sd=sigma))
  # Cumul des espèces découvertes
  sum_S[i+1] <- sum_S[i] + S[i]
}
# Figure
tibble(Y, S) %>% 
  ggplot() +
    geom_line(aes(x=Y, y=S)) +
    scale_y_log10()
```


# Inférence

## Données 

Le nombre d'observations est `nTemps`.
Les unités de temps sont dans le vecteur `Y`.
```{r}
nTemps <- nTemps  # A remplacer par les vraies données
Y <- 1:nTemps
```


La variable expliquée est $S$.
Le nombre d'espèces décrites au début de la période d'étude est $S_0$.
```{r}
S <- S            # A remplacer par les vraies données
S_0 <- sum_S[1]   # A remplacer par les vraies données
```

La variable explicative est :

- $T$ : le nombre de taxonomistes actifs chaque année.
```{r}
T <- T            # A remplacer par les vraies données
```

Les paramètres sont $\theta = (\beta_1, \beta_2, S_T, \sigma)$.


## Vraisemblance

La vraisemblance des données `S` sachant les paramètres est calculée :
```{r}
# Arguments:
# S : nombre d'espèces découvertes au temps i
# T : nombre de taxonomistes 
# Y : année (temps)
# S_0 : nombres d'espèces connues au début
# theta : paramètres
ll_S_theta <- function(S, T, Y, S_0, theta) {
  nTemps <- length(Y)
  # Stockage des prédictions du modèle et de leur cumul
  prediction <- numeric(nTemps)
  sum_S <- numeric(nTemps+1)
  # Valeur initiale
  sum_S[1] <- S_0
  # Valeurs prédites par le modèle
  for (i in 1:nTemps) {
    prediction[i] <- (theta[3] * theta[1] * T[i]
            + theta[2] * theta[3] * T[i] * Y[i]
            + theta[1] * T[i] * sum_S[i]
            + theta[2] * T[i] * Y[i] * sum_S[i])
    sum_S[i + 1] <- sum_S[i] + prediction[i]
  }
  # Log-vraisemblance de chaque valeur de y
  likelihoods <- suppressWarnings(dnorm(log(S), mean = log(prediction), sd = theta[4], log = TRUE))
  # Possibilité de NaN 
  ll <- sum(likelihoods)
  # Vraisemblance nulle dans ce cas
  if (is.na(ll)) 
    ll <- -Inf
  return(ll)
}
```

La vraisemblance des paramètres est:
```{r}
ll_prior <- function(theta, S_0) {
    # Log-vraisemblance de chaque paramètre dans sa loi a priori
    prior1 <- dunif(theta[1], min = 0, max = 1E-2, log = TRUE)   # beta_1
    prior2 <- dunif(theta[2], min = 0, max = 1E-3, log = TRUE)   # beta_2
    prior3 <- dunif(theta[3], min = S_0, max = 1E6, log = TRUE)  # S_T
    prior4 <- dunif(theta[4], min = 0, max = 1000, log = TRUE)   # sigma
    return(prior1 + prior2 + prior3 + prior4)
}
```


## Parcours de l'espace des paramètres

Fonction de proposition :
```{r}
proposal <- function(theta, sigma_prop) {
    return(rnorm(length(theta), mean = theta, sd = sigma_prop))
}
```

Chaîne de Markov :
```{r} 
MetropolisMCMC <- function(S, T, Y, S_0, sigma_prop, theta_0, iterations) {
    # Stockage. Chaque ligne du tableau contient une itération ; les colonnes contiennent theta
    chain <- matrix(nrow = iterations + 1, ncol = length(theta_0))
    # Noms des paramètres
    colnames(chain) <- names(theta_0)
    # Stockage des vraisemblances (1: ll_S_theta, 2: ll_prior)
    ll_data <- matrix(nrow = iterations + 1, ncol = 2)
    colnames(ll_data) <- c("data", "prior")
    # Valeurs initiales
    chain[1, ] <- theta_0
    ll_data[1, 1] <- ll_S_theta(S, T, Y, S_0, theta_0)
    ll_data[1, 2] <- ll_prior(theta_0, S_0)
    # Initialisation d'une barre de progression
    pgb <- txtProgressBar(min = 0, max = iterations)
    # Chaîne de Markov
    for (i in 1:iterations) {
        # Proposition d'une valeur de theta
        theta_proposal <- proposal(chain[i, ], sigma_prop)
        # Vraisemblances
        ll_data[i + 1, 1] <- ll_S_theta(S, T, Y, S_0, theta_proposal)
        ll_data[i + 1, 2] <- ll_prior(theta_proposal, S_0)
        # Acceptation
        if (sum(ll_data[i, ]) == -Inf) {
          # Acceptation systématique si la vraisemblance précédente était nulle
          l_ratio <- Inf
        } else {
        # Rapport de vraisemblance entre la proposition et la valeur précédente de theta
          l_ratio <- exp(sum(ll_data[i + 1, ]) - sum(ll_data[i, ]))
        }
        # Acceptation ou non
        if (runif(1) < l_ratio) {
            chain[i + 1, ] <- theta_proposal
        } else {
            chain[i + 1, ] <- chain[i, ]
            # Conserver les valeurs de vraisemblance
            ll_data[i + 1, ] <- ll_data[i, ]
        }
        setTxtProgressBar(pgb, i)
    }
    # Retour d'un tableau complet: theta et vraisemblance
    return(cbind(chain, LogVraisemblance = ll_data))
}
```


## Exécution

```{r}
# Nombre de pas de la chaîne
iterations <- 1e+6
# Ecart-type de la marche aléatoire (pour chaque paramètre)
sigma_prop <- c(2E-5, 2E-7, 3000, 2E-2)
# Valeur initiale des paramètres
theta_0 <- c(
  beta_1/2,   # beta_1
  beta_2/2,   # beta_2
  S_T/2,      # S_T
  sigma/2     # sigma
  )
names(theta_0) <- c("beta_1", "beta_2", "S_T", "EcartType")
# Lancement de la chaîne de Markov
chain <- MetropolisMCMC(S, T, Y, S_0, sigma_prop, theta_0, iterations)
```


## Résultats

```{r}
# Evolution de la vraisemblance
par(mfrow = c(1, 2))
plot(chain[, length(theta_0) + 1], type = "l", main = "Evolution de la vraisemblance", xlab = "Pas", ylab = "log Vraisemblance")
burn_in <- iterations/10
plot(chain[-(1:burn_in), length(theta_0) + 1], type = "l", main = "Après convergence", xlab = "Pas", ylab = "log Vraisemblace")
```

Evolution des paramètres:
```{r}
par(mfrow = c(2, 2))
plot(chain[-(1:burn_in), 1], type = "l", main = "", xlab = "beta_1", ylab = "")
plot(chain[-(1:burn_in), 2], type = "l", main = "", xlab = "beta_2", ylab = "")
plot(chain[-(1:burn_in), 3], type = "l", main = "", xlab = "S_T", ylab = "")
plot(chain[-(1:burn_in), 4], type = "l", main = "", xlab = "sigma", ylab = "")
```


## Taux d'acceptation

```{r}
# Taux d'acceptation de la chaine de Markov
(acceptance <- 1 - mean(duplicated(chain[-(1:burn_in), ])))
```

## Distribution des paramètres

```{r}
par(mfrow = c(1, length(theta_0)))
for (i in 1:length(theta_0)) {
    Titre <- paste("Distribution de", names(theta_0)[i])
    Mediane <- format(median(chain[-(1:burn_in), i]), digits = 4)
    hist(chain[-(1:burn_in), i], xlab = paste("Mediane :", Mediane), main = Titre)
    abline(v = Mediane, col = "red")
}
```


## Autocorrélation

```{r}
acf(chain[-(1:burn_in), 1:(ncol(chain)-2)], lag.max = 1000)
```
Eclaircie:
```{r}
# Distribution a posteriori. Elimination du prechauffage et de la vraisemblance, éclaircie.
posterior <- chain[-(1:burn_in), 1:(ncol(chain)-2)][seq(1, 
    iterations - burn_in, by = 500), ]
# Nouvelle distribution des paramètres
par(mfrow = c(1, length(theta_0)))
for (i in 1:length(theta_0)) {
    Titre <- paste("Distribution de", names(theta_0)[i])
    Mediane <- format(median(posterior[, i]), digits = 4)
    hist(posterior[, i], xlab = paste("Mediane :", Mediane), main = Titre)
    abline(v = Mediane, col = "red")
}
```
Nouvelle autocorrélation:
```{r}
acf(posterior, lag.max = 100)
```


# Inférence à partir des données réelles

## Données

```{r}
data <- read.csv2("data/Lombrics.csv")
data <- data[data$S>0, ]
```


Les unités de temps sont dans le vecteur `Y`.
```{r}
Y <- data$Y # Première année : 1826, chaque période dure 5 ans
nTemps <- length(Y)
```


La variable expliquée est $S$.
Le nombre d'espèces décrites au début de la période d'étude est $S_0$.
```{r}
S <- data$S
S_0 <- 1   # L. terrestris par Linné 
```

La variable explicative est :

- $T$ : le nombre de taxonomistes actifs à chaque période.
```{r}
T <- data$T
```


## Prior

La vraisemblance des paramètres est:
```{r}
ll_prior <- function(theta, S_0) {
    # Log-vraisemblance de chaque paramètre dans sa loi a priori
    prior1 <- dunif(theta[1], min = 0, max = 1, log = TRUE)   # beta_1
    prior2 <- dunif(theta[2], min = 0, max = 1, log = TRUE)   # beta_2
    prior3 <- dunif(theta[3], min = S_0, max = 1E6, log = TRUE)  # S_T
    prior4 <- dunif(theta[4], min = 0, max = 1000, log = TRUE)   # sigma
    return(prior1 + prior2 + prior3 + prior4)
}
```


## Exécution

```{r}
# Nombre de pas de la chaîne
iterations <- 1e+5
# Ecart-type de la marche aléatoire (pour chaque paramètre)
sigma_prop <- c(1E-1, 1E-2, 1E6, 10)/100
# Valeur initiale des paramètres
theta_0 <- c(
  1E-3,  # beta_1
  1E-4,  # beta_2
  5E4,   # S_T
  10     # sigma
  )
names(theta_0) <- c("beta_1", "beta_2", "S_T", "EcartType")
# Lancement de la chaîne de Markov
chain <- MetropolisMCMC(S, T, Y, S_0, sigma_prop, theta_0, iterations)
```


## Résultats

```{r}
# Evolution de la vraisemblance
par(mfrow = c(1, 2))
plot(chain[, length(theta_0) + 1], type = "l", main = "Evolution de la vraisemblance", xlab = "Pas", ylab = "log Vraisemblance")
burn_in <- iterations/10
plot(chain[-(1:burn_in), length(theta_0) + 1], type = "l", main = "Après convergence", xlab = "Pas", ylab = "log Vraisemblace")
```

Evolution des paramètres:
```{r}
par(mfrow = c(2, 2))
plot(chain[-(1:burn_in), 1], type = "l", main = "", xlab = "beta_1", ylab = "")
plot(chain[-(1:burn_in), 2], type = "l", main = "", xlab = "beta_2", ylab = "")
plot(chain[-(1:burn_in), 3], type = "l", main = "", xlab = "S_T", ylab = "")
plot(chain[-(1:burn_in), 4], type = "l", main = "", xlab = "sigma", ylab = "")
```


## Taux d'acceptation

```{r}
# Taux d'acceptation de la chaine de Markov
(acceptance <- 1 - mean(duplicated(chain[-(1:burn_in), ])))
```

## Distribution des paramètres

```{r}
par(mfrow = c(1, length(theta_0)))
for (i in 1:length(theta_0)) {
    Titre <- paste("Distribution de", names(theta_0)[i])
    Mediane <- format(median(chain[-(1:burn_in), i]), digits = 4)
    hist(chain[-(1:burn_in), i], xlab = paste("Mediane :", Mediane), main = Titre)
    abline(v = Mediane, col = "red")
}
```


## Autocorrélation

```{r}
acf(chain[-(1:burn_in), 1:(ncol(chain)-2)], lag.max = 1000)
```
Eclaircie:
```{r}
# Distribution a posteriori. Elimination du prechauffage et de la vraisemblance, éclaircie.
posterior <- chain[-(1:burn_in), 1:(ncol(chain)-2)][seq(1, 
    iterations - burn_in, by = 500), ]
# Nouvelle distribution des paramètres
par(mfrow = c(1, length(theta_0)))
for (i in 1:length(theta_0)) {
    Titre <- paste("Distribution de", names(theta_0)[i])
    Mediane <- format(median(posterior[, i]), digits = 4)
    hist(posterior[, i], xlab = paste("Mediane :", Mediane), main = Titre)
    abline(v = Mediane, col = "red")
}
```
Nouvelle autocorrélation:
```{r}
acf(posterior, lag.max = 100)
```